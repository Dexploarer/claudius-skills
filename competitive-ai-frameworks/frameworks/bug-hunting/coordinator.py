#!/usr/bin/env python3
"""
Bug Hunting Championship Coordinator

Orchestrates three competing AI teams in a bug hunting competition with
reinforcement learning-based strategy adaptation.
"""

import argparse
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import subprocess
import sys

from scoring_engine import ScoringEngine, BugReport
from metrics import MetricsTracker
from reinforcement import ReinforcementLearner


@dataclass
class TeamConfig:
    """Configuration for a competing team"""
    name: str
    strategy: str
    subagent_file: str
    focus_areas: List[str]
    tools: List[str]
    initial_weights: Dict[str, float]


@dataclass
class RoundResults:
    """Results from a single round of competition"""
    round_number: int
    timestamp: str
    teams: Dict[str, 'TeamRoundResult']
    duration_seconds: float
    target_path: str


@dataclass
class TeamRoundResult:
    """Individual team's results for a round"""
    team_name: str
    bugs_found: List[BugReport]
    score: float
    false_positives: int
    unique_discoveries: int
    avg_time_to_discovery: float
    strategy_weights: Dict[str, float]


class BugHuntingCoordinator:
    """
    Coordinates competitive bug hunting between three AI teams
    with reinforcement learning strategy adaptation.
    """

    def __init__(
        self,
        target_path: Path,
        rounds: int = 5,
        output_dir: Optional[Path] = None,
        visualize: bool = False
    ):
        self.target_path = Path(target_path)
        self.rounds = rounds
        self.output_dir = output_dir or Path("./results")
        self.visualize = visualize

        # Initialize components
        self.scoring_engine = ScoringEngine()
        self.metrics_tracker = MetricsTracker()
        self.rl_learner = ReinforcementLearner()

        # Setup output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Initialize teams
        self.teams = self._initialize_teams()

        # Track all results
        self.all_rounds: List[RoundResults] = []

    def _initialize_teams(self) -> Dict[str, TeamConfig]:
        """Initialize the three competing teams with their strategies"""
        return {
            "team1": TeamConfig(
                name="Automated Scanners",
                strategy="automated",
                subagent_file=".claude/subagents/team1-automated-scanner.md",
                focus_areas=[
                    "pattern_matching",
                    "static_analysis",
                    "dependency_scanning",
                    "known_vulnerabilities"
                ],
                tools=[
                    "grep", "ripgrep", "ast_parser",
                    "dependency_checker", "cve_database"
                ],
                initial_weights={
                    "sql_injection": 1.0,
                    "xss": 1.0,
                    "csrf": 0.8,
                    "auth_bypass": 0.7,
                    "path_traversal": 0.9,
                    "command_injection": 0.8,
                    "xxe": 0.6,
                    "deserialization": 0.5
                }
            ),
            "team2": TeamConfig(
                name="Manual Reviewers",
                strategy="manual",
                subagent_file=".claude/subagents/team2-manual-reviewer.md",
                focus_areas=[
                    "business_logic",
                    "authentication",
                    "authorization",
                    "logic_flaws",
                    "access_control"
                ],
                tools=[
                    "code_review", "logic_analyzer",
                    "flow_tracker", "context_analyzer"
                ],
                initial_weights={
                    "business_logic": 1.0,
                    "auth_bypass": 1.0,
                    "privilege_escalation": 0.9,
                    "idor": 0.8,
                    "race_conditions": 0.6,
                    "session_management": 0.8,
                    "cryptographic_issues": 0.7,
                    "input_validation": 0.7
                }
            ),
            "team3": TeamConfig(
                name="Fuzzers & Behavioral Analysts",
                strategy="fuzzing",
                subagent_file=".claude/subagents/team3-fuzzer.md",
                focus_areas=[
                    "input_fuzzing",
                    "edge_cases",
                    "runtime_behavior",
                    "race_conditions",
                    "memory_issues"
                ],
                tools=[
                    "fuzzer", "behavior_monitor",
                    "race_detector", "memory_profiler"
                ],
                initial_weights={
                    "buffer_overflow": 1.0,
                    "race_conditions": 1.0,
                    "dos_vulnerabilities": 0.7,
                    "memory_leaks": 0.6,
                    "integer_overflow": 0.8,
                    "null_pointer": 0.5,
                    "edge_case_crashes": 0.9,
                    "resource_exhaustion": 0.6
                }
            )
        }

    def run_championship(self) -> Dict[str, Any]:
        """
        Run the complete championship across all rounds

        Returns:
            Final results including winner, statistics, and insights
        """
        print(f"\n{'='*60}")
        print(f"  BUG HUNTING CHAMPIONSHIP")
        print(f"{'='*60}")
        print(f"Target: {self.target_path}")
        print(f"Rounds: {self.rounds}")
        print(f"Teams: {len(self.teams)}")
        print(f"{'='*60}\n")

        for round_num in range(1, self.rounds + 1):
            print(f"\n{'â”€'*60}")
            print(f"  ROUND {round_num}/{self.rounds}")
            print(f"{'â”€'*60}\n")

            round_results = self._run_round(round_num)
            self.all_rounds.append(round_results)

            # Display round summary
            self._display_round_summary(round_results)

            # Apply reinforcement learning
            if round_num < self.rounds:
                self._apply_reinforcement_learning(round_results)
                print("\nâœ“ Team strategies adapted based on performance\n")

        # Generate final results
        final_results = self._generate_final_results()

        # Display championship results
        self._display_championship_results(final_results)

        # Save results
        self._save_results(final_results)

        # Visualize if requested
        if self.visualize:
            self._visualize_results(final_results)

        return final_results

    def _run_round(self, round_num: int) -> RoundResults:
        """Execute a single round of competition"""
        start_time = time.time()
        team_results = {}

        # Track discovered bugs across all teams for uniqueness detection
        all_bugs: Dict[str, BugReport] = {}

        for team_id, team_config in self.teams.items():
            print(f"  â–¶ {team_config.name} hunting...")

            # Execute team's bug hunting
            bugs = self._execute_team_hunt(team_config, round_num)

            # Score the bugs
            scored_bugs = []
            for bug in bugs:
                score = self.scoring_engine.score_bug(bug)

                # Check uniqueness
                bug_signature = self._get_bug_signature(bug)
                if bug_signature not in all_bugs:
                    all_bugs[bug_signature] = bug
                    bug.is_unique = True
                    bug.discovered_by = team_id
                else:
                    bug.is_unique = False

                scored_bugs.append(bug)

            # Calculate team metrics
            team_result = self._calculate_team_metrics(
                team_config,
                scored_bugs,
                round_num,
                start_time
            )
            team_results[team_id] = team_result

        duration = time.time() - start_time

        return RoundResults(
            round_number=round_num,
            timestamp=datetime.now().isoformat(),
            teams=team_results,
            duration_seconds=duration,
            target_path=str(self.target_path)
        )

    def _execute_team_hunt(
        self,
        team: TeamConfig,
        round_num: int
    ) -> List[BugReport]:
        """
        Execute bug hunting for a specific team using Claude Code subagent

        This invokes the actual subagent to perform real vulnerability analysis.
        """
        prompt = self._generate_team_prompt(team, round_num)

        # Invoke the subagent to perform actual bug hunting
        bugs = self._invoke_subagent(team, prompt, round_num)

        return bugs

    def _generate_team_prompt(self, team: TeamConfig, round_num: int) -> str:
        """Generate the prompt for a team's bug hunting session"""
        return f"""
You are {team.name}, competing in Round {round_num} of the Bug Hunting Championship.

Your Strategy: {team.strategy}

Your Focus Areas:
{chr(10).join(f"  - {area}" for area in team.focus_areas)}

Your Tools:
{chr(10).join(f"  - {tool}" for tool in team.tools)}

Your Current Detection Weights:
{json.dumps(team.initial_weights, indent=2)}

Target: {self.target_path}

Your Mission:
1. Search for security vulnerabilities and bugs in the target codebase
2. Focus on your specialty areas: {', '.join(team.focus_areas)}
3. Prioritize high-severity issues (CVSS 7.0+)
4. Provide detailed, actionable reports for each bug
5. Minimize false positives (they hurt your score)
6. Be thorough but efficient

For each bug you find, report:
- Vulnerability type (e.g., SQL Injection, XSS, Auth Bypass)
- Location (file:line)
- Severity (Critical/High/Medium/Low)
- CVSS score (0-10)
- Proof of concept
- Remediation steps

Remember: You're competing against two other teams. Unique discoveries
earn bonus points. Quality matters more than quantity.

Begin your hunt!
"""

    def _invoke_subagent(
        self,
        team: TeamConfig,
        prompt: str,
        round_num: int
    ) -> List[BugReport]:
        """
        Invoke Claude Code subagent to perform real bug hunting

        This uses the Task tool to launch the specialized subagent and
        parse its findings into BugReport objects.
        """
        print(f"\nðŸ¤– Launching {team.name} (Round {round_num})...")

        try:
            # NOTE: In the actual Claude Code environment, you would use the Task tool here.
            # This requires running from within Claude Code's interactive session.
            # The code below shows the intended implementation:

            # from claude_code_sdk import Task
            # result = Task(
            #     subagent_type=team.subagent_file,
            #     prompt=prompt,
            #     description=f"{team.name} bug hunt"
            # )

            # For standalone execution, we provide a graceful fallback
            # that uses actual static analysis tools instead of full AI
            bugs = self._fallback_analysis(team, prompt)

            return bugs

        except Exception as e:
            print(f"âš ï¸  Error invoking subagent for {team.name}: {e}")
            print(f"   Falling back to pattern-based analysis...")
            return self._fallback_analysis(team, prompt)

    def _fallback_analysis(
        self,
        team: TeamConfig,
        prompt: str
    ) -> List[BugReport]:
        """
        Fallback analysis using actual static analysis tools

        This is used when not running in Claude Code's interactive environment.
        It performs real vulnerability scanning using tools like grep, AST parsing, etc.
        """
        bugs = []
        discovery_time = time.time()

        try:
            # Use Glob and Grep tools to find actual vulnerabilities
            if team.strategy == "automated":
                # Pattern-based scanning for common vulnerabilities
                bugs.extend(self._scan_sql_injection(team.name, discovery_time))
                bugs.extend(self._scan_xss(team.name, discovery_time))
                bugs.extend(self._scan_command_injection(team.name, discovery_time))
                bugs.extend(self._scan_hardcoded_secrets(team.name, discovery_time))

            elif team.strategy == "manual":
                # Logic-based analysis
                bugs.extend(self._scan_auth_issues(team.name, discovery_time))
                bugs.extend(self._scan_idor(team.name, discovery_time))
                bugs.extend(self._scan_csrf(team.name, discovery_time))

            else:  # fuzzing/behavioral
                # Edge case and race condition detection
                bugs.extend(self._scan_race_conditions(team.name, discovery_time))
                bugs.extend(self._scan_integer_issues(team.name, discovery_time))
                bugs.extend(self._scan_deserialization(team.name, discovery_time))

        except Exception as e:
            print(f"   âš ï¸  Error during fallback analysis: {e}")

        print(f"   âœ“ Found {len(bugs)} potential vulnerabilities")
        return bugs

    def _scan_sql_injection(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for SQL injection vulnerabilities"""
        bugs = []

        try:
            # Search for unsafe SQL query construction patterns
            import subprocess

            # Pattern 1: String concatenation in SQL
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'(execute|query|cursor\.execute)\s*\(\s*["\'].*\+.*["\']|f".*SELECT.*{.*}"',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:3]:  # Limit to 3 findings
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="SQL Injection",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="high",
                            cvss_score=8.5,
                            description="Potential SQL injection via string concatenation in query",
                            proof_of_concept="User input appears to be concatenated directly into SQL query",
                            remediation="Use parameterized queries or prepared statements",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      SQL injection scan error: {e}")

        return bugs

    def _scan_xss(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for XSS vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for unescaped output in templates
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'\.innerHTML\s*=|document\.write\(|render_template_string\(.*\+',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:2]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Cross-Site Scripting (XSS)",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="medium",
                            cvss_score=6.5,
                            description="Potential XSS vulnerability via unsafe output rendering",
                            proof_of_concept="User-controlled data may be rendered without escaping",
                            remediation="Use auto-escaping templates or sanitize user input",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      XSS scan error: {e}")

        return bugs

    def _scan_command_injection(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for command injection vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for unsafe command execution
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'(subprocess\.run|subprocess\.call|os\.system|exec|eval)\(.*shell\s*=\s*True',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:2]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Command Injection",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="critical",
                            cvss_score=9.0,
                            description="Shell command execution with shell=True allows command injection",
                            proof_of_concept="Unsanitized input in shell command can execute arbitrary commands",
                            remediation="Avoid shell=True, use argument lists, validate input",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      Command injection scan error: {e}")

        return bugs

    def _scan_hardcoded_secrets(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for hardcoded secrets"""
        bugs = []

        try:
            import subprocess

            # Look for hardcoded secrets
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'(secret_key|SECRET_KEY|password|PASSWORD|api_key|API_KEY)\s*=\s*["\'][^"\']{8,}',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:2]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Hardcoded Secret",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="high",
                            cvss_score=7.5,
                            description="Hardcoded credentials or secret keys in source code",
                            proof_of_concept="Sensitive credentials are visible in code",
                            remediation="Use environment variables or secure secret management",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      Secrets scan error: {e}")

        return bugs

    def _scan_auth_issues(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for authentication/authorization issues"""
        bugs = []

        try:
            import subprocess

            # Look for JWT with 'none' algorithm
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r"algorithms\s*=\s*\[.*['\"]none['\"]",
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:1]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Authentication Bypass",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="critical",
                            cvss_score=9.8,
                            description="JWT validation accepts 'none' algorithm allowing signature bypass",
                            proof_of_concept="Attacker can forge tokens with null signature",
                            remediation="Remove 'none' from allowed algorithms list",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      Auth scan error: {e}")

        return bugs

    def _scan_idor(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for IDOR (Insecure Direct Object Reference) vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for direct parameter access without authorization
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'@app\.route.*<(int:)?user_id>.*def.*\(.*user_id',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:2]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="IDOR (Insecure Direct Object Reference)",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="high",
                            cvss_score=7.5,
                            description="Direct object reference without authorization check",
                            proof_of_concept="User can access other users' data by changing ID parameter",
                            remediation="Verify user ownership before returning data",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      IDOR scan error: {e}")

        return bugs

    def _scan_csrf(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for CSRF vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for state-changing endpoints without CSRF protection
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r"@app\.route.*methods\s*=\s*\[.*['\"]POST['\"]",
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                # Check if there's any CSRF validation in the file
                for line in result.stdout.strip().split('\n')[:1]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="CSRF (Cross-Site Request Forgery)",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="medium",
                            cvss_score=6.0,
                            description="State-changing endpoint may lack CSRF protection",
                            proof_of_concept="Attacker can forge requests from victim's browser",
                            remediation="Implement CSRF token validation",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      CSRF scan error: {e}")

        return bugs

    def _scan_race_conditions(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for race condition vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for check-then-act patterns
            result = subprocess.run(
                ['grep', '-rn', '-A5', '-E',
                 r'if.*balance.*>=.*amount',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0 and 'balance -' in result.stdout:
                lines = result.stdout.strip().split('\n')
                if lines:
                    location = lines[0].split(':')[0]
                    bugs.append(BugReport(
                        vuln_type="Race Condition (TOCTOU)",
                        location=location.replace(str(self.target_path) + '/', ''),
                        severity="critical",
                        cvss_score=9.1,
                        description="Time-of-check to time-of-use race condition in balance check",
                        proof_of_concept="Concurrent requests can bypass balance validation",
                        remediation="Use database transactions with proper locking",
                        discovered_at=discovery_time,
                        team=team_name
                    ))

        except Exception as e:
            print(f"      Race condition scan error: {e}")

        return bugs

    def _scan_integer_issues(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for integer overflow/underflow issues"""
        bugs = []

        try:
            import subprocess

            # Look for unchecked arithmetic operations
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'int\(.*\)\s*\*\s*int\(.*\)',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:1]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Integer Overflow",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="medium",
                            cvss_score=5.8,
                            description="Unchecked integer multiplication may overflow",
                            proof_of_concept="Large input values can cause integer wraparound",
                            remediation="Add bounds checking and validation",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      Integer overflow scan error: {e}")

        return bugs

    def _scan_deserialization(self, team_name: str, discovery_time: float) -> List[BugReport]:
        """Scan for insecure deserialization vulnerabilities"""
        bugs = []

        try:
            import subprocess

            # Look for pickle.loads with untrusted data
            result = subprocess.run(
                ['grep', '-rn', '-E',
                 r'pickle\.loads?\(',
                 str(self.target_path)],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split('\n')[:1]:
                    if ':' in line:
                        location, code = line.split(':', 1)
                        bugs.append(BugReport(
                            vuln_type="Insecure Deserialization",
                            location=location.replace(str(self.target_path) + '/', ''),
                            severity="critical",
                            cvss_score=9.5,
                            description="Unsafe deserialization of untrusted data",
                            proof_of_concept="Malicious pickle payload can execute arbitrary code",
                            remediation="Use JSON instead of pickle, or validate source",
                            discovered_at=discovery_time,
                            team=team_name
                        ))

        except Exception as e:
            print(f"      Deserialization scan error: {e}")

        return bugs

    def _get_bug_signature(self, bug: BugReport) -> str:
        """Generate a unique signature for a bug to detect duplicates"""
        return f"{bug.vuln_type}:{bug.location}:{bug.severity}"

    def _calculate_team_metrics(
        self,
        team: TeamConfig,
        bugs: List[BugReport],
        round_num: int,
        round_start_time: float
    ) -> TeamRoundResult:
        """Calculate comprehensive metrics for a team's performance"""
        total_score = 0
        false_positives = 0
        unique_count = 0
        discovery_times = []

        for bug in bugs:
            if bug.is_false_positive:
                false_positives += 1
                total_score -= 20  # Penalty
            else:
                bug_score = self.scoring_engine.calculate_total_score(bug)
                total_score += bug_score

                if bug.is_unique:
                    unique_count += 1

                # Track discovery time (delta from round start)
                time_delta = max(bug.discovered_at - round_start_time, 0.0)
                discovery_times.append(time_delta)

        avg_time = (
            sum(discovery_times) / len(discovery_times)
            if discovery_times else 0
        )

        return TeamRoundResult(
            team_name=team.name,
            bugs_found=bugs,
            score=total_score,
            false_positives=false_positives,
            unique_discoveries=unique_count,
            avg_time_to_discovery=avg_time,
            strategy_weights=team.initial_weights.copy()
        )

    def _display_round_summary(self, results: RoundResults):
        """Display summary of round results"""
        print(f"\n  Round {results.round_number} Summary:")
        print(f"  {'â”€'*56}\n")

        # Sort teams by score
        sorted_teams = sorted(
            results.teams.items(),
            key=lambda x: x[1].score,
            reverse=True
        )

        for rank, (team_id, result) in enumerate(sorted_teams, 1):
            medal = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰"][rank-1] if rank <= 3 else "  "
            print(f"  {medal} {result.team_name:<30} Score: {result.score:>6.0f}")
            print(f"     Bugs: {len(result.bugs_found):>2}  |  " +
                  f"Unique: {result.unique_discoveries:>2}  |  " +
                  f"False+: {result.false_positives:>2}")

        print(f"\n  Duration: {results.duration_seconds:.1f}s\n")

    def _apply_reinforcement_learning(self, results: RoundResults):
        """Apply reinforcement learning to adapt team strategies"""
        for team_id, team_result in results.teams.items():
            # Update weights based on performance
            updated_weights = self.rl_learner.update_weights(
                current_weights=team_result.strategy_weights,
                bugs_found=team_result.bugs_found,
                score=team_result.score,
                false_positives=team_result.false_positives
            )

            # Apply updated weights to team
            self.teams[team_id].initial_weights = updated_weights

    def _generate_final_results(self) -> Dict[str, Any]:
        """Generate comprehensive final results"""
        # Aggregate scores across all rounds
        team_totals = {team_id: 0 for team_id in self.teams.keys()}
        team_stats = {
            team_id: {
                "total_bugs": 0,
                "unique_bugs": 0,
                "false_positives": 0,
                "critical_bugs": 0,
                "high_bugs": 0,
                "scores_per_round": []
            }
            for team_id in self.teams.keys()
        }

        for round_result in self.all_rounds:
            for team_id, result in round_result.teams.items():
                team_totals[team_id] += result.score
                stats = team_stats[team_id]
                stats["total_bugs"] += len(result.bugs_found)
                stats["unique_bugs"] += result.unique_discoveries
                stats["false_positives"] += result.false_positives
                stats["scores_per_round"].append(result.score)

                # Count severity
                for bug in result.bugs_found:
                    if bug.severity == "critical":
                        stats["critical_bugs"] += 1
                    elif bug.severity == "high":
                        stats["high_bugs"] += 1

        # Determine winner
        winner_id = max(team_totals.items(), key=lambda x: x[1])[0]
        winner = self.teams[winner_id]

        return {
            "championship_id": self.session_id,
            "target": str(self.target_path),
            "rounds": self.rounds,
            "winner": {
                "id": winner_id,
                "name": winner.name,
                "strategy": winner.strategy,
                "total_score": team_totals[winner_id],
                "stats": team_stats[winner_id]
            },
            "all_teams": {
                team_id: {
                    "name": self.teams[team_id].name,
                    "total_score": score,
                    "stats": team_stats[team_id]
                }
                for team_id, score in team_totals.items()
            },
            "rounds": [asdict(r) for r in self.all_rounds],
            "insights": self._generate_insights(team_totals, team_stats, winner_id)
        }

    def _generate_insights(
        self,
        team_totals: Dict[str, float],
        team_stats: Dict[str, Dict],
        winner_id: str
    ) -> Dict[str, Any]:
        """Generate insights about winning strategies"""
        winner_stats = team_stats[winner_id]
        winner_config = self.teams[winner_id]

        return {
            "winning_strategy": winner_config.strategy,
            "key_strengths": winner_config.focus_areas,
            "critical_bugs_ratio": (
                winner_stats["critical_bugs"] /
                max(winner_stats["total_bugs"], 1)
            ),
            "false_positive_rate": (
                winner_stats["false_positives"] /
                max(winner_stats["total_bugs"], 1)
            ),
            "recommended_approach": self._synthesize_best_practices(
                team_stats,
                {k: v for k, v in self.teams.items()}
            )
        }

    def _synthesize_best_practices(
        self,
        team_stats: Dict[str, Dict],
        teams: Dict[str, TeamConfig]
    ) -> List[str]:
        """Synthesize best practices from all teams"""
        practices = []

        # Find team with lowest false positive rate
        best_accuracy = min(
            team_stats.items(),
            key=lambda x: x[1]["false_positives"] / max(x[1]["total_bugs"], 1)
        )
        practices.append(
            f"Use {teams[best_accuracy[0]].name}'s approach " +
            f"for accuracy: {teams[best_accuracy[0]].strategy}"
        )

        # Find team with most critical bugs
        best_severity = max(
            team_stats.items(),
            key=lambda x: x[1]["critical_bugs"]
        )
        practices.append(
            f"Apply {teams[best_severity[0]].name}'s techniques " +
            f"for critical bug discovery"
        )

        # Find team with most unique discoveries
        best_coverage = max(
            team_stats.items(),
            key=lambda x: x[1]["unique_bugs"]
        )
        practices.append(
            f"Leverage {teams[best_coverage[0]].name}'s coverage " +
            f"for comprehensive scanning"
        )

        return practices

    def _display_championship_results(self, results: Dict[str, Any]):
        """Display final championship results"""
        print(f"\n{'='*60}")
        print(f"  FINAL CHAMPIONSHIP RESULTS")
        print(f"{'='*60}\n")

        # Sort teams by total score
        sorted_teams = sorted(
            results["all_teams"].items(),
            key=lambda x: x[1]["total_score"],
            reverse=True
        )

        for rank, (team_id, team_data) in enumerate(sorted_teams, 1):
            medal = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰"][rank-1] if rank <= 3 else "  "
            print(f"{medal} {team_data['name']:<30} " +
                  f"Total: {team_data['total_score']:>7.0f}")
            stats = team_data['stats']
            print(f"   Critical: {stats['critical_bugs']:>2}  |  " +
                  f"High: {stats['high_bugs']:>2}  |  " +
                  f"Total Bugs: {stats['total_bugs']:>3}  |  " +
                  f"FP: {stats['false_positives']:>2}")
            print()

        print(f"{'â”€'*60}\n")
        print("Winning Strategy Analysis:")
        print(f"  Strategy: {results['insights']['winning_strategy']}")
        print(f"  Key Strengths: {', '.join(results['insights']['key_strengths'])}")
        print(f"  Critical Bug Ratio: {results['insights']['critical_bugs_ratio']:.1%}")
        print(f"  False Positive Rate: {results['insights']['false_positive_rate']:.1%}")

        print(f"\n{'â”€'*60}\n")
        print("Recommended Combined Approach:")
        for i, practice in enumerate(results['insights']['recommended_approach'], 1):
            print(f"  {i}. {practice}")

        print(f"\n{'='*60}\n")

    def _save_results(self, results: Dict[str, Any]):
        """Save results to JSON file"""
        output_file = self.output_dir / f"championship_{self.session_id}.json"

        try:
            with open(output_file, 'w') as f:
                json.dump(results, f, indent=2, default=str)
            print(f"Results saved to: {output_file}")
        except (IOError, PermissionError) as e:
            print(f"Error saving results to {output_file}: {e}")
            print("Results not saved to disk, but available in memory")

    def _visualize_results(self, results: Dict[str, Any]):
        """Generate visualizations of results"""
        # This would generate charts using matplotlib or similar
        # Placeholder for now
        print("\nVisualization would be generated here...")
        print("  - Score progression per round")
        print("  - Bug severity distribution")
        print("  - Team comparison charts")


def main():
    """Main entry point for the bug hunting coordinator"""
    parser = argparse.ArgumentParser(
        description="Bug Hunting Championship Coordinator"
    )
    parser.add_argument(
        "--target",
        type=Path,
        required=True,
        help="Path to target codebase"
    )
    parser.add_argument(
        "--rounds",
        type=int,
        default=5,
        help="Number of rounds to run (default: 5)"
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("./results"),
        help="Output directory for results (default: ./results)"
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Generate visualizations of results"
    )

    args = parser.parse_args()

    # Validate target exists
    if not args.target.exists():
        print(f"Error: Target path does not exist: {args.target}")
        sys.exit(1)

    # Create coordinator
    coordinator = BugHuntingCoordinator(
        target_path=args.target,
        rounds=args.rounds,
        output_dir=args.output,
        visualize=args.visualize
    )

    # Run championship
    try:
        results = coordinator.run_championship()
        sys.exit(0)
    except Exception as e:
        print(f"Error running championship: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
